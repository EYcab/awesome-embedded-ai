---
layout: default
---

# 嵌入式AI简报 (2019-04-28)

**关注模型压缩、低比特量化、移动端推理加速优化、部署**  
<font>注：PC端微信链接打不开请用手机打开</font>


## 业界新闻

- [英特尔“演化算法”新框架：29个Python代码块，自动生成新算法 | 新智元](https://mp.weixin.qq.com/s/q93z9cio7GwjXR36PgU16w) [[论文]](https://arxiv.org/abs/1904.02830)  
摘要：英特尔的研究人员提出一种新的自动算法生成器（AAD），利用演化算法框架，以Python语言的基本子集作为语法架构，能够对29个数组/向量问题的代码块进行组合，通过学习，自动生成更复杂问题的解决方案。  
自动算法发现器（AAD），这是一种用于合成高复杂度计算程序的演化算法框架。此前的演化算法依赖于客观的适应函数，这在给算法设计上增加了难度。  
AAD是用于综合高复杂度程序的演化框架，它以Python语言的基本子集作为语法架构。使用AAD能够对29个数组/向量问题的代码块进行组合，其中既有最大值、最小值，矩阵翻转这类简单问题，也有更具挑战性的问题，如排序和矩阵向量乘法等，对于输入没有大小限制。  
为了应对复杂需求带来的各种挑战，AAD工具还能实现与高性能计算（HPC）技术的结合。总的来说，与现有技术相比，采用PGE的演化算法能够解决类似或更高复杂性的问题。


## 论文

- [SysML] [Accurate and Efficient 2-Bit Quantized Neural Netowrks](https://www.sysml.cc/doc/2019/168.pdf) [[机器之心解读]](https://mp.weixin.qq.com/s/HzgRHtVwdmW6_m7OJwK-ew)  
摘要：为得到整体的量化神经网络（QNN），这篇论文提出分别用于权重和激活的量化技术：
    1. 激活量化的技术「PArameterized Clipping acTivation（PACT）」：在训练期间使用 ReLU 函数的参数化截略来确定量化的输出范围的方案；
    2. 用于权重量化的技术「Statistics-Aware Weight Binning（SAWB）」：可基于权重分布的统计特性确定能最小化量化误差的最优比例因子，无需执行穷举搜索。
组合使用 PACT 与 SAWB 可以得到一种二位量化神经网络（2-bit QNN），其分类准确度在一些常见的模型和数据集上能达到当前最佳水平。
- [SysML] [Optimizing DNN Computation With Relaxed Graph Substitution](https://www.sysml.cc/doc/2019/22.pdf) [[机器之心解读]](https://mp.weixin.qq.com/s/HzgRHtVwdmW6_m7OJwK-ew)  
摘要：DNN 可被视为由（数学）算子组成的计算图。TensorFlow、PyTorch 和 TVM 等会将计算表达为有状态的数据流图，并在训练期间优化图，并会在整个过程中变换为新图。新图相比于迭代前的图通常会有严格更好的运行时间性能。这种「严格更好」会得到深度学习框架的非常受限的搜索空间，也是高计算成本的一大原因。直观地说，可以认为优化问题存在诸多约束。约束越多，算法得到解的时间就会越长。  
例如，如果 conv3 是一个 3×3 卷积，其核可分解为使用两个 1×3 核执行卷积（6 次乘法）但结果还是一样，从计算角度看，每次卷积的成本更低了。此外，通过将卷积分为两个可以并行执行的更小卷积，执行整个卷积的速度也可能会更快。  
这一思路两个方向都有效，而且这正是图替换思想背后的基本直觉。如果源图和目标图计算出的输出在外部边上是数学上等价的，则图替代就是有效的。最后说明一点，宽松化的思路可按如下方式展示。考虑以下等价表达式以及从上面的表达式到下面的表达式所采取的步骤：  
![graph-opt](https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibRziaEw20HY7S6ToICwUH9Z8uJ6XOdWQdX6mtlIJPUO7XYRLG2nFgDDDSXGFxfrnEHaLL06ToupSw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)  
但是，如果系统每次迭代时都有约束——新子图必须严格优于当前子图；则第二个表达式就不会被允许，因此也就无法得到最终的表达式。这就体现了放松约束条件（宽松化）的重要性。   
因此为了解决这个问题从而降低计算成本，这篇论文提出了一种宽松化的图替代方法，可通过放松每个迭代约束的「严格更好」来实现复杂图优化的探索。这能增大问题的可行空间，并能在每次迭代时更快找到解。此外，研究者还引入了回溯方法（backtracking），可搜索一组宽松化图替代来寻找每次迭代的最优解（没有严格更好的约束）。


## 开源项目

- [用Modin利用多核加速Pandas计算 | 机器之心解读](https://mp.weixin.qq.com/s/QDTMvvCUN71_L4nPgqzN1Q)  
Modin 是加州大学伯克利分校 RISELab 的一个早期项目，旨在促进分布式计算在数据科学领域的应用。它是一个多进程的数据帧（Dataframe）库，具有与 Pandas 相同的应用程序接口（API），使用户可以加速他们的 Pandas 工作流。  
例如，在一台 8 核的机器上，用户只需要修改一行代码，Modin 就能将 Pandas 查询任务加速 4 倍。Modin 所做的只是增加了 CPU 所有内核的利用率，从而提供了更好的性能。该系统是为希望程序运行得更快、伸缩性更好，而无需进行重大代码更改的 Pandas 用户设计的。这项工作的最终目标是能够在云环境中使用 Pandas。
    1. Modin 的架构数据帧分区，Modin对数据帧的分区模式是沿着列和行同时进行划分的，因为这样为 Modins 在支持的列数和行数上都提供了灵活性和可伸缩性。
    ![modin](https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibr720w0uHY8x7z0xwEkmur3yr8gkUYtkI1lxheYuPHYjnGJu0X1xIqLA7m5ibS0ZjFqAtAxYXx4PA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)  
    2. Modin 系统架构被分为不同的层：
        1. Pandas API 在最顶层暴露给用户。
        2. 下一层为查询编译器，它接收来自 Pandas API 层的查询并执行某些优化。
        3. 最后一层为分区管理器（Partition Manager），负责数据布局并对发送到每个分区的任务进行重组、分区和序列化。
        ![modin-architecture](https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibr720w0uHY8x7z0xwEkmur0pKNNnO7KWLuiajKdX8ia449zHybdibY797VTeibA4PV2o2pQpkHTibcl8A/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)
Modin 利用 [Ray](http://github.com/ray-project/ray) 加速 Pandas 的 notebook、脚本和程序库。Ray 是一个针对大规模机器学习和强化学习应用的高性能分布式执行框架。同样的代码可以在单台机器上运行以实现高效的多进程，也可以在集群上用于大型计算。
        
## 博文

## [往期回顾](https://github.com/ysh329/awesome-embedded-ai)

- [2019-04-13](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-04-13.md)  
- [2019-03-31](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-03-31.md)  

----

Editor: https://github.com/ysh329  
Project: https://github.com/ysh329/awesome-embedded-ai  

----

<a rel="license" href="http://creativecommons.org/licenses/by-sa/2.0/"><img alt="知识共享许可协议" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/2.0/88x31.png" /></a><br />本作品采用<a rel="license" href="http://creativecommons.org/licenses/by-sa/2.0/">知识共享署名-相同方式共享 2.0 通用许可协议</a>进行许可。
