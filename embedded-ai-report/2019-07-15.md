---
layout: default
---

# 嵌入式AI简报 (2019-07-15)

**关注模型压缩、低比特量化、移动端推理加速优化、部署**  
<font>注：PC端微信链接打不开请用手机打开</font>


## 业界新闻 

- [麒麟810实体芯片首次亮相，对标骁龙730，AI跑分比骁龙855还高 | 量子位](https://mp.weixin.qq.com/s/WdWkm8rs978rMl216K-xAA)  
摘要：麒麟810，2+6大小核：两颗主频2.27GHz的Cortex-A76大核，六颗主频1.88GHz的Cortex-A55小核。Mali-G52定制六核。  
在AI Benchmark官网上，麒麟810的芯片数据得分为23944，位居第一。不仅超过了骁龙855，也超过了华为首款7nm芯片麒麟980。  
麒麟810的强项在于处理FP16数据格式的性能和能效表现，与骁龙855相比有6-8倍的优势。此外，在Int8的精度保留和超分性能上也挺好，在图片处理中细节更清晰，不会出现画面错误。  
- [亚毫秒级手机人脸识别！谷歌BlazeFace算法重大突破， 面向移动GPU | 新智元](https://mp.weixin.qq.com/s/kDQSO0zS_EflsRGNH8bAvQ)  
摘要：BlazeFace包括一个轻量级的特征提取网络，其灵感来自于MobileNetV1/V2，但又有所不同。还采取了一种修改过的SSD目标检测算法，使其对GPU更加友好。然后用改进的联合分辨率（tie resolution）策略来替代非极大抑制（Non-maximum suppression）。  
BlazeFace可用于检测智能手机前置摄像头捕捉到的图像中的一个或多个人脸。返回的是一个边界框和每个人脸的6个关键点。  
- [Google提出全新间接卷积算法 | AI科技大本营](https://mp.weixin.qq.com/s/Q1Ovl1LrT5Y6amVqlYpdbA)  
摘要：谷歌的Peter Vajda在ECV2019中提出了一种全新的间接卷积算法，用于改进GEMM在实现卷积操作时存在的一些缺点，进而提升计算效率。  


## 论文

- [CVPR2019: 压缩AI模型有望部署于移动终端 | 戚琦 网络智能研究中心NIRC](https://mp.weixin.qq.com/s/zoUpCxifuPBKbNjjAZWN6g)  
摘要：在这篇由北京邮电大学网络智能研究中心、东信北邮EB Lab合作完成的论文中，作者考虑了网络中连续层之间的关联关系，提出了OICSR方法，将结构正则化同时运用于连续网络层中相互对应的out-channels和in-channels，从而可以在更小的精度损失下，移除更多的冗余通道。在对指标影响较小的情况下，极大地提升深度学习模型的运行效率。

## 开源项目

- [taylorguo/MTCNN_Landmark106: ncnn优化MTCNN, 模型来源于https://github.com/MirrorYuChen/ncnn_106landmarks](https://github.com/taylorguo/MTCNN_Landmark106)  



## 博文

- [通用矩阵乘（GEMM）优化与卷积计算 | 黎明灰烬 博客](https://jackwish.net/gemm-optimization-and-convolution.html)  
摘要：本文简要介绍通用矩阵乘（GEMM，General Matrix Multiplication）优化的基本概念和方法、神经网络量化中矩阵乘的优化方法。旨在帮助大家在概念中建立一些直觉，无甚高论。  
- [NCNN量化详解（二） | 知乎](https://zhuanlan.zhihu.com/p/72375164)  
摘要：上次写了一个量化详解，讲了一下NCNN的量化前传过程。本以为是全部内容了，经评论区提醒NCNN最近刚刚更新了量化表的计算，因此写一篇文章把NCNN的量化表计算的算法与实现写下来。  
- [华为中兴7nm芯片欢乐“斗地主” | AI报道](https://mp.weixin.qq.com/s?__biz=Mzg2NzEzNzk3Ng==&mid=2247489896&amp;idx=1&amp;sn=393e4f02c6711beecb1b000ca274d0db&source=41#wechat_redirect)  
摘要：目前，全球7nm旗舰手机芯片一共有4颗，华为就独占了2颗 。荣耀产品副总裁熊军民打趣地说道：“打麻将有点占便宜了，欢迎友商来斗地主”。而近日中兴又带来了好消息，国内即将迎来第三款7nm芯片。华为“斗地主”的局又多了一员。虽然国内芯片设计行业频繁带来利好消息，但我们还不应该欣喜过早。毕竟，产业链中游芯片制造业还处在困境之中，一时无法破解。  
- [PaddlePaddle显存分配与优化最佳实践 | 飞桨PaddlePaddle](https://mp.weixin.qq.com/s/23q81aXS2FjzrQhQfPTkOA)  
摘要：先说飞桨显存分配策略，由于原生的CUDA系统调用 cudaMalloc 和 cudaFree 均是同步操作，非常耗时。为了加速显存分配，飞桨采用了显存预分配的策略，
除了显存预分配，飞桨还提供了多种通用显存优化方法，使得同样网络模型及配置下的显存占用尽可能小，从而可以支持更大batch size的训练，来提升训练效率，也将会介绍最重要的两种方法，分别是GC（Garbage Collection）策略和Inplace策略。  
- [CPU是如何访问内存的 | Peter盼 人人都是极客](https://mp.weixin.qq.com/s/iyTRMFYTd5PYRVxng1Al4w)  
摘要：内存管理可以说是一个比较难学的模块，之所以比较难学。一是内存管理涉及到硬件的实现原理和软件的复杂算法，二是网上关于内存管理的解释有太多错误的解释。希望可以做个内存管理的系列，从硬件实现到底层内存分配算法，再从内核分配算法到应用程序内存划分，一直到内存和硬盘如何交互等，彻底理解内存管理的整个脉络框架。本节主要讲解硬件原理和分页管理。  
摘要：



## [往期回顾](https://github.com/ysh329/awesome-embedded-ai)

- [2019-06-29](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-06-29.md)
- [2019-06-17](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-06-17.md)
- [2019-05-30](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-05-30.md)  
- [2019-05-15](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-05-15.md)  
- [2019-04-27](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-04-27.md)  
- [2019-04-13](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-04-13.md)  
- [2019-03-31](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-03-31.md)  

----

![wechat_qrcode](../wechat_qrcode.jpg)

Wechat ID: NeuroMem  
Editor: https://github.com/ysh329  
Project: https://github.com/ysh329/awesome-embedded-ai  

----

<a rel="license" href="http://creativecommons.org/licenses/by-sa/2.0/"><img alt="知识共享许可协议" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/2.0/88x31.png" /></a><br />本作品采用<a rel="license" href="http://creativecommons.org/licenses/by-sa/2.0/">知识共享署名-相同方式共享 2.0 通用许可协议</a>进行许可。
