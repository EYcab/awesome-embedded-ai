---
layout: default
---

# 嵌入式AI简报 (2019-09-16)

**关注模型压缩、低比特量化、移动端推理加速优化、部署**  
<font>注：PC端微信链接打不开请用手机打开</font>


## 业界新闻  

- [A13 Bionic 芯片，苹果发布会的真正亮点 | Tinc V  雷锋网](https://mp.weixin.qq.com/s/h75Xvm_vEyBDz13ki9ty7Q)  
摘要：A13 Bionic 集成 85 亿个晶体管，采用 7nm 工艺，专为高性能和低功耗而量身定制：  
CPU 方面，拥有 2 颗高性能核心，速度提升 20%，功耗降低 30%；拥有 4 颗效能核心，速度提升 20%，功耗降低了 40%；CPU 还上新增了两个新的机器学习加速器，能以最高达过去六倍的速度执行矩阵数学运算，让中央处理器每秒可进行一万亿次运算；一般情况下，仅依靠 4 颗效能核心，新 iPhone 就可以正常运转；另外 2 颗高性能核心可在特殊情况下被智能调用。  
GPU 方面，为四核心设计，速度提升 20%，功耗降低 40%；在现场，苹果还专门通过一款游戏来展现其优异的 GPU 图形处理能力。  
AI 方面，有一个八核神经引擎（Nerual Engine），性能提升了 20%，功耗降低 15%；为三摄系统、Face ID、增强现实类 app 和更多功能提供强大驱动力。
- [华为麒麟990发布！余承东：全球首款旗舰5G SoC，业界最强手机AI算力，友商还都是PPT | 量子位](https://mp.weixin.qq.com/s/O2_A8Ifvfh_2tbJVOAkb9Q)  
摘要：麒麟990 5G采用2个超大核（基于Cortex-A76开发）+2个大核（基于Cortex-A76开发）+4个小核（Cortex-A55）架构。  最高主频可达2.86GHz，与骁龙855相比，单核性能高10%，多核性能高9%。能效方面针对不同大小的核精细调校，大核能效优12%，中核能效优35%，小核能效优15%。  
GPU方面，麒麟990 5G提升到了16核Mali-G76 GPU，同样与骁龙855相比，图形处理性能高6%，能效优20%。  
- [Android 10 正式发布：具备先进 AI 能力，支持 5G 手机 | 安卓开发者博客](https://mp.weixin.qq.com/s/CjKjOlXYXQp20fm9qAzT7g)  
摘要：Android 10 是围绕三大主题打造的：首先，Android 10 正在引领移动创新潮流，其具备先进的机器学习能力，并对可折叠和 5G 手机等新兴前沿设备提供了支持；其次，Android 10 高度关注隐私和安全性，通过近 50 项功能为用户提供更好的安全保护、透明度和控制权；最后，Android 10 增强了用户对数字生活的控制能力，使个人和家庭可以更好地从技术中获益。  
- [三星发布5G SoC Exynos 980 | 安兔兔](https://mp.weixin.qq.com/s/WovuNkRv6-KjJ2jTwTGnuQ)  
摘要：三星正式官宣了旗下的全新SoC Exynos 980，其最大的特色就是集成了5G基带，基于8nm工艺打造。  
规格方面，内置两颗2.2GHz的Cortex-A77核心和六颗1.8GHz的A55核心，GPU为Mali-G76 MP5，最高支持3360×1440分辨率屏幕，同时内置有NPU，存储方面支持LPDDR4X内存以及UFS 2.1/eMMC 5.1闪存。    
官方称NPU的AI性能相比上代产品有2.7倍提升，通过NPU可增加应用程序的增强功能，如安全用户身份验证，内容过滤，混合现实，智能相机等。      
- [边缘AI服务器EAIS，赋能全行业终端设备输出AI能力 | OPEN AI LAB  开放智能机器](https://mp.weixin.qq.com/s/AW3dAJFYAovMv5Y2omGvAg)  
摘要：EAIS（Edge AI Server）是OPEN AI LAB联合产业合作伙伴，共同打造了软件定义硬件的边缘AI计算平台系列产品，由三大部分构成：  
  1. 高性能的嵌入式硬件平台（适配1-16T多种算力形态）；  
  2. AIoT应用开发框架Tengine；  
  3. 业务层算法级应用Solution；  
综合，为客户及合作伙伴提供一个高开发效率、灵活适配的AI边缘平台。  
- [NVDLA Deep Learning Inference Compiler is Now Open Source | devblogs.nvidia.com](https://devblogs.nvidia.com/nvdla/)  
摘要：Designing new custom hardware accelerators for deep learning is clearly popular, but achieving state-of-the-art performance and efficiency with a new design is a complex and challenging problem.  
Two years ago, NVIDIA opened the source for the hardware design of the NVIDIA Deep Learning Accelerator (NVDLA) to help advance the adoption of efficient AI inferencing in custom hardware designs. The same NVDLA is shipped in the NVIDIA Jetson AGX Xavier Developer Kit, where it provides best-in-class peak efficiency of 7.9 TOPS/W for AI. With the open-source release of NVDLA’s optimizing compiler on GitHub, system architects and software teams now have a starting point with the complete source for the world’s first fully open software and hardware inference platform.  
In this blog we’ll explain the role that a network graph compiler plays in the key goal of achieving power efficiency in a purpose-built hardware accelerator, and we’ll show you how to get started by building and running your own custom NVDLA software and hardware design in the cloud.

## 论文


## 开源项目

- [ShuffleNet Series开源啦 | 旷视研究院](https://mp.weixin.qq.com/s/Nm9PnyM0tA6mWeqGBCpVdA)  
摘要：ShuffleNet Series涵盖以下6个模型：  
  1. ShuffleNetV1: ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices  
  2. ShuffleNetV2: ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design  
  3. ShuffleNetV2+: ShuffleNetV2 的增强版  
  4. ShuffleNetV2.Large: ShuffleNetV2 的深化版  
  5. OneShot  
  6. DetNAS: DetNAS: Backbone Search for Object Detection  
- [支持微信的 TensorFlow | https://github.com/tensorflow/tfjs-wechat](https://github.com/tensorflow/tfjs-wechat)  
摘要：用于微信小程序的 TensorFlow.js 插件，该插件封装了 TensorFlow.js 库，用于提供给第三方小程序调用。  
在小程序管理后台的「第三方服务-插件管理」中添加插件，就能直接在小程序上部署机器学习模型。更便捷的是，我们可以直接从 tfjs 模型库调用预训练模型，不论是视觉、语音还是自然语言相关的能力。此外，为了方便国内开发者的使用，该插件的 URL 调用参数都提供了国内镜像，这样才能流畅地打造整个小程序。  
- [alipay/SoloPi: Soloπ 自动化测试工具 | https://github.com/alipay/SoloPi](https://github.com/alipay/SoloPi)
- [PyTorch语音工具包SpeechBrain要来了，支持多种语音任务，实现最强水准 | 量子位](https://mp.weixin.qq.com/s/qcQfySe9-Sgz0tgWpbtZIQ)  
摘要：图灵奖得主、AI三巨头之一Yoshua Bengio领衔的研究机构Mila宣布，要联合英伟达、杜比、三星、PyTorch官方、IBM AI研究院等公司和机构，做一个新的开源一体化语音工具包：SpeechBrain。这个工具包将会非常全能，能用来做语音识别（end-to-end & HMM-DNN）、说话人识别、语音分离，多麦克风信号处理（beamforming）、自我监督和无监督学习、语音增强等任务。  
SpeechBrain会建立在PyTorch上，并且和PyTorch官方合作，所有功能都在PyTorch中实现，当然，用的是Python，不是C++。并且，SpeechBrain将会设计成一个独立的框架，会有Kaldi这类常用的工具包的接口。   
- [李沐等人的开源中文书《动手学深度学习》现在有 PyTorch 版实现了 | https://github.com/ShusenTang/Dive-into-DL-PyTorch](项目地址：https://github.com/ShusenTang/Dive-into-DL-PyTorch)  
摘要：不论是原书中的示例代码，还是实战项目，原来的 MXNet 都可以无缝转化到 PyTorch 代码。项目作者在保持原书内容基本不变的情况下，将 MXNet 代码都转换为了 PyTorch，想要学习 DL 和 PyTorch 的小伙伴们可以试试。  
- [TensorFlow Lite + AoE ：基于深度学习的驾驶安全之路 | TensorFlow](https://mp.weixin.qq.com/s/okMKu5gYggq133IB7IigNQ)  
摘要：AoE ( AI on Edge ) 是滴滴近期开源的终端侧 AI 集成运行时环境 ( IRE )：https://github.com/didi/AoE  
终端侧落地一些具体的 AI 业务时，会发现有些不得不面对的问题：除了要做推理框架选型，还需要关注数据预 / 后处理逻辑的稳定性，模型分发使用时的包大小、数据安全等问题。  
这也正是 AoE 的设计初衷，希望完善模型生产到落地应用链路上的各个环节，提供整套的工具支撑体系，帮助开发者在终端轻松部署 AI 模型。以下我们通过滴滴内部一个具体实例应用，介绍 AoE 如何搭档 TensorFlow Lite ，让终端侧 AI 开发变得更加简单。


## 博文


- [为什么还用A76 ? 麒麟990 详细解析 | 易建芯](https://mp.weixin.qq.com/s/3K_5YL57i_KyhqzlqUt-rQ)  
摘要：虽然A77达到了更高的峰值性能，但A77和A76在7nm上的功率效率实际上是相同的，但是由于A76在7nm上的体验更好，能将核心频率推得更高。据报道，其他拥有A77产品的公司在其他晶圆厂采用类似的工艺技术时，只能达到2.2 GHz。据说A77很可能会在未来5nm变得更加广泛可用时的产品中出现。      
- [Roofline Model与深度学习模型的性能分析 | 机器学习笔记](https://zhuanlan.zhihu.com/p/34204282)   
摘要：最近在不同的计算平台上验证几种经典深度学习模型的训练和预测性能时，经常遇到模型的实际测试性能表现和自己计算出的复杂度并不完全吻合的现象，令人十分困惑。机缘巧合听了Momenta的技术分享后，我意识到问题的答案其实就在于 Roof-line Model 这个理论。  
- [如何实现高速卷积？深度学习库使用了这些「黑魔法」 | 机器之心](https://mp.weixin.qq.com/s/RaW_WVKoLBk6jkoA6A3D-A)  
摘要：本文尝试介绍在DNN库中如何实现一个卷积层。卷积不仅是很多DNN模型中最常见和最繁重的操作，它也是导致上述高性能实现的代表性trick：一点点算法智慧 + 大量调参 + 充分利用低级架构。  
本文所涉及的很多内容来自这篇开创性论文《Anatomy of High-Performance Matrix Multiplication》，这篇论文形成了线性代数库（如OpenBLAS）所用算法的基础；本文还涵盖 Stefan Hadjis 博士和 Chris Rose的教程。  
论文地址：https://www.cs.utexas.edu/~flame/pubs/GotoTOMS_revision.pdf  
教程地址：https://cs.stanford.edu/people/shadjis/blas.html  
- [利用 NVIDIA TensorRT 进行Tiny YOLO v2 推理应用 | Tsutomu Furuse 吉浦迅科技](https://mp.weixin.qq.com/s/mWiPNBI5Skl8Wq_upSi9vQ)  
摘要：从Open Neural Network eXchange (ONNX) model Zoo下载 Tiny YOLO v2模型，并将其转换为NVIDIA TensorRT，然后开始对摄像头捕获的图像进行目标检测。  
- [LLVM中目标无关(Target-Indepenent)的代码生成(Code Generator) | ChsLLVMDocs](https://github.com/wuye9036/ChsLLVMDocs/blob/master/CodeGen.md)  


## [往期回顾](https://github.com/ysh329/awesome-embedded-ai)


- [2019-08-30](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-08-30.md)
- [2019-08-15](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-08-15.md)
- [2019-07-30](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-07-30.md)
- [2019-07-15](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-07-15.md)
- [2019-06-29](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-06-29.md)
- [2019-06-17](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-06-17.md)
- [2019-05-30](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-05-30.md)  
- [2019-05-15](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-05-15.md)  
- [2019-04-27](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-04-27.md)  
- [2019-04-13](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-04-13.md)  
- [2019-03-31](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-03-31.md)  

----

![wechat_qrcode](../wechat_qrcode.jpg)

Wechat ID: NeuroMem  
Editor: https://github.com/ysh329  
Project: https://github.com/ysh329/awesome-embedded-ai  

----

<a rel="license" href="http://creativecommons.org/licenses/by-sa/2.0/"><img alt="知识共享许可协议" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/2.0/88x31.png" /></a><br />本作品采用<a rel="license" href="http://creativecommons.org/licenses/by-sa/2.0/">知识共享署名-相同方式共享 2.0 通用许可协议</a>进行许可。
