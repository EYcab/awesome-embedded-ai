---
layout: default
---

# 嵌入式AI简报 (2019-12-17)

**关注模型压缩、低比特量化、移动端推理加速优化、部署**  


## 业界新闻

- [苹果5nm A14处理器：和华为抢产能 | 安兔兔](https://mp.weixin.qq.com/s/Msww0DBSM4qd-kPtDJK1KA)  
摘要：按照苹果的惯例，明年秋季发布的iPhone 12系列将配备全新的A14处理器，目前产业链已经给出了A14处理器的部分信息。  
产业链透露，苹果A14处理器将采用台积电的5nm工艺制造，明年初开始小范围试产，第二季度将正式量产。目前台积电5nm工艺的客户基本上只有苹果和海思，对应的产品分别是A14处理器以及麒麟1000系列SoC。  
产能方面，据称目前台积电5nm工艺的良率可达50%以上，预计最快明年第一季度量产，初期月产能5万片，随后将逐步增加到7~8万片。  
全新的5nm工艺相比7nm来说有何提升呢？按照台积电官方数据，相较于7nm（第一代DUV），基于Cortex A72核心的全新5nm芯片能够提供1.8倍的逻辑密度、速度增快15%，或者功耗降低30%，同样制程的SRAM也十分优异且面积缩减。  
- [华为中端神U麒麟820，亮相 6nm工艺 | 安兔兔](https://mp.weixin.qq.com/s/taUeCMJSRtzaeG6_z-h6UA)  
摘要：SoC命名为麒麟820，将采用三星6nm制程工艺，几乎没有成本限制，将于今年第二季度量产，很可能会集成5G基带。  
消息指出，6nm意味着芯片单位空间能容纳更多晶体管数量，相比台积电7nm工艺有着更多的EUV层，提供额外18%的密度改进，理论上同面积芯片的运算能力也就更强。  
此前爆料的消息称，麒麟1020定位旗舰级别，代号巴尔的摩(Baltimore)，基于台积电5nm工艺制造，同时内置晶体管继续增加（麒麟990 5G集成103亿个），CPU架构升级到Cortex-A78，相比麒麟990来说性能提升可达50%。
- [探境量产不到一年，AI语音芯片出货量达百万级 | 雷锋网](https://mp.weixin.qq.com/s/mt5YWJs7Tv_uYAud6W19KQ)  
摘要：探境科技设计出的非冯诺依曼架构的计算架构——存储构SFA（Storage First Architecture）。SFA架构解决内存墙挑战的方法比较独特，以存储调度为核心的计算架构，数据在存储之间的搬移过程之中就完成了计算，计算对于数据来说只是一种演变。  
SFA架构实现的方法是通过硬件、架构调度、数据调度管理等创新。实验数据表明，SFA架构所采用的各种微观和宏观调度算法，比较’类CPU架构‘采用的基于总线和指令集的映射方法，在近似存储量、近似算力、近似外部存储带宽、近似功耗约束的前提下，可以获得8~12倍的利用率收益。”鲁勇表示。  
其量化技术，硬件上提供一些比较冗余的信息，保证即使量化为8比特也不会丢失信息。同时借助AI、非线性的一套算法，通过软硬结合的方式，甚至可以做到量化到4比特，模型都不需要重新训练。  
- [比手工模型快10~100倍，谷歌揭秘视频NAS三大法宝 | 机器之心](https://mp.weixin.qq.com/s/0kGJfKARKs2TuIQ4YJYbUA)  
摘要：Tiny Video Networks（TinyVideoNets）有很高的准确率和运行效率，能够以实时或更高的速度高效运行。要想识别大约 1 秒钟的视频片段，在 CPU 上只需要运行 37 至 100 ms，在 GPU 上只需要运行 10 ms，比以前手动设计的网络快了数百倍。  
模型架构的设计，是通过演化过程中明确定义模型运行时间，并限制算法探索的搜索空间（同时包括空间和时间分辨率以及通道大小）得到的，实现了性能的提升。

## 论文


## 开源项目

- [移动设备“性能缩水”成常态？我们带来了避坑指南 | 三易生活](https://mp.weixin.qq.com/s/pVTUB7sNdYW0-sPD8pdNhA)  
摘要：在手机、笔记本、平板这样的移动设备上，顶配与“顶级性能”之间的关系，却似乎正在变得有些模糊。  
相同硬件不同性能？最新的跑分数据揭开秘密。最早发现这个问题的，是海外媒体NotebookCheck。早在数月之前，这家媒体在做评测时发现，许多笔记本电脑，特别是轻薄本都存在CPU在测试中降频的问题。  
- [5nm工艺问世，CPU工艺与性能是一种什么样的关系 | strongerHuang](https://mp.weixin.qq.com/s/4z-4Fd17BT7tnVe5iLNTBw)  
摘要：现在半导体工艺上所说的多少nm工艺其实是指线宽，也就是芯片上的最基本功能单位门电路的宽度，因为实际上门电路之间连线的宽度同门电路的宽度相同，所以线宽可以描述制造工艺。缩小线宽意味着晶体管可以做得更小、更密集，而且在相同的芯片复杂程度下可使用更小的晶圆，于是成本降低了。  
更先进半导体制造工艺另一个重要优点就是可以提升工作频率，缩减元件之间的间距之后，晶体管之间的电容也会降低，晶体管的开关频率也得以提升，从而整个芯片的工作频率就上去了。  
- [微软开源自动机器学习工具NNI概览及新功能详解 | 微软研究院AI头条](https://mp.weixin.qq.com/s/7_KRT-rRojQbNuJzkjFMuA)  
摘要：微软亚洲研究院发布了第一版 NNI (Neural Network Intelligence) ，目前已在 GitHub 上获得 3.8K 星，成为最热门的自动机器学习（AutoML）开源项目之一。  
作为为研究人员和算法工程师量身定制的自动机器学习工具和框架，NNI 在过去一年中不断迭代更新，我们发布了稳定 API 的 1.0 版本，并且不断将最前沿的算法加入其中，加强对各种分布式训练环境的支持。  
最新版本的 NNI 对机器学习生命周期的各个环节做了更加全面的支持，包括特征工程、神经网络架构搜索（NAS）、超参调优和模型压缩在内的步骤，你都能使用自动机器学习算法来完成。  
项目地址：https://github.com/microsoft/nni  



- [模型加速5个方法供参考附代码 | AI科技大本营](https://mp.weixin.qq.com/s/RpTQ4lirj0mlMUFeM8mrtw)  
摘要：诸如权重稀疏化等模型裁剪方法的核心思路是去掉那些不重要的权重和链接，整个网络的权重变少了，那么模型自然而然也就变小了，但是这种方法会带来比较明显的信息丢失，虽然我们会在最后的性能与模型体积中采取一种折中的方案，但性能的损失最后还是不可避免的。在下面的内容中，我们就和大家讨论并分享工业界的权重压缩，deepCompression，二值化，三值化，DoReFa-net。

## 博文

- [深度剖析AI芯片初创公司Graphcore的IPU | StarryHeavensAbove](https://mp.weixin.qq.com/s/qP0zsSA7SQWXDqWGEAXmOg)  
摘要：2017年我曾经基于Graphcore的CTO Simon Knowles的演讲两次分析了它们的AI芯片。最近，我们看到更多关于IPU的信息，包括来自第三方的详细分析和Graphcore的几个新的演讲。基于这些信息，我们可以进一步勾勒（推测）出IPU的架构设计的一些有趣细节。  
- [卷积神经网络在移动端集成显卡上的加速 | 知乎tvm专栏](https://zhuanlan.zhihu.com/p/99660496)  
摘要：本文谈的是在移动端加速卷积神经网络。虽然AWS是个云服务公司，但只要可能，都希望计算在本地解决。  
好处：减小网络带宽压力，避免网络传输时延，用户数据安全。现代终端设备一般用一个片上系统 (SoC)做计算，上面有CPU和集成显卡。  
虽然移动端的CPU（多数ARM，少数x86）优化实现相对简单（参见我们对CPU的优化），但此处它并非最佳选择，因为：1）移动端CPU算力一般弱于集成显卡（相差在2-6倍之间）；2）更重要的是，已经有很多程序运行在CPU上，如果将模型推理也放在上面会导致CPU耗能过大或者CPU节流，造成耗电过快同时性能不稳定。所以在移动端进行模型计算，集成显卡是更好的选择。  
- [GELU：BERT、GPT-2等都在用的激活函数，超越ReLU却鲜为人知 | 机器之心](https://mp.weixin.qq.com/s/LEPalstOc15CX6fuqMRJ8Q)  
摘要：GELU 激活函数，随着 x 的降低，它被归零的概率会升高。对于 ReLU 来说，这个界限就是 0，输入少于零就会被归零。这一类激活函数，不仅保留了概率性，同时也保留了对输入的依赖性。  
我们可以理解为，对于一部分Φ(x)，它直接乘以输入 x，而对于另一部分 (1 − Φ(x))，它们需要归零。不太严格地说，上面这个表达式可以按当前输入 x 比其它输入大多少来缩放 x。  
研究者对比了在视觉或语言任务中，Swish 效果要比GELU更好一些。在NLP领域里，GELU已经成为了众多最佳模型的选择。  
- [安兔兔2019年度最强性能SoC评奖 | 安兔兔](https://mp.weixin.qq.com/s/8MS3ss2gMxQ1cyIh5nLDVQ)  
摘要：以评奖方式回顾2019年的手机SoC，同时在每个层次选出最具代表性的SoC给出奖项，分别是旗舰性能奖、技术创新奖，以及最具性价比奖。  


## [往期回顾](https://github.com/ysh329/awesome-embedded-ai)

- [2019-12-17](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-12-17.md)
- [2019-12-02](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-12-02.md)
- [2019-11-18](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-11-18.md)
- [2019-10-31](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-10-31.md)
- [2019-10-17](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-10-17.md)  
- [2019-10-03](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-10-03.md)  
- [2019-09-16](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-09-16.md)
- [2019-08-30](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-08-30.md)
- [2019-08-15](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-08-15.md)
- [2019-07-30](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-07-30.md)
- [2019-07-15](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-07-15.md)
- [2019-06-29](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-06-29.md)
- [2019-06-17](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-06-17.md)
- [2019-05-30](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-05-30.md)  
- [2019-05-15](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-05-15.md)  
- [2019-04-27](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-04-27.md)  
- [2019-04-13](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-04-13.md)  
- [2019-03-31](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-03-31.md)  

----

![wechat_qrcode](../wechat_qrcode.jpg)

Wechat ID: NeuroMem  
Editor: https://github.com/ysh329  
Project: https://github.com/ysh329/awesome-embedded-ai  

----

<a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"><img alt="知识共享许可协议" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" /></a><br />本作品采用<a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">知识共享署名-相同方式共享 4.0 通用许可协议</a>进行许可。
