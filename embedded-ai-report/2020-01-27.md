---
layout: default
---

# 嵌入式AI简报 (2020-01-27)

**关注模型压缩、低比特量化、移动端推理加速优化、部署**  


## 业界新闻

- iPhone 12采用5纳米A14处理器，性能堪比MacBook Pro | IT之家  
摘要：1月17日，据国外媒体报道， iPhone 12将采用5纳米制造工艺的A14处理器，配备ToF 3D摄像头（AR能力和人像模式显著提升）和6GB RAM，支持5G网络。5纳米工艺意味着A14芯片可能拥有125亿个晶体管，甚至比桌面和服务器CPU更多。此外，苹果还可以将芯片面积缩小至约85平方毫米，这将使其性能大幅提升，尤其是在多核性能方面。有分析师称，iPhone 12的性能几乎可以匹敌15英寸MacBook Pro笔记本电脑。  
- [Qualcomm推出三款全新骁龙移动平台460，662，720以满足对4G智能手机的持续需求 | Qualcomm中国](https://mp.weixin.qq.com/s/2BO_UXIY1qGoqLlp5tdYMQ)  
摘要：因为比较关注CPU/GPU/DSP部分，简单摘录了一下。  
骁龙720G支持最新的第五代Qualcomm® AI Engine，集成了增强的Qualcomm® Hexagon™张量加速器。  
骁龙460是面向新一代大众市场智能手机的移动平台，在骁龙4系中实现了性能的巨大飞跃，同时在连接、AI和拍摄等方面也有显著的提升。骁龙460首次在骁龙4系中引入CPU性能内核以及新的GPU架构，分别实现了70%和60%的性能提升。整体系统性能是前代平台的2倍。骁龙460还首次在骁龙4系中引入了支持HVX的Hexagon处理器，因此通过对第三代Qualcomm AI Engine的支持再加上Qualcomm传感器中枢，可为拍摄和语音助理带来全新的AI体验。  
骁龙662首次将令人惊叹的拍摄和AI功能带入骁龙6系。支持Hexagon向量扩展内核（HVX）的第三代Qualcomm AI Engine与Qualcomm Spectra 340T ISP一起。  
- [搜狗地图：国内首个手机 AR 实景驾驶导航上线，还能识别车辆行人 | 量子位](https://mp.weixin.qq.com/s/3WBQtHzqI4oaDfrDYHKiPg)  
摘要：搜狗地图支持手机 AR 实景行车驾驶导航，能贴合道路给出路径指引，转弯处还有立体箭头引导，能够识别车辆、行人，及时给出碰撞预警，夜间识别，也不在话下。无需额外购买昂贵的设备，只需一台手机，一个App，即可体验。  

## 论文

- [推理速度提升29倍，参数少1/10，阿里提出AdaBERT压缩方法 | 机器之心](https://mp.weixin.qq.com/s/mObuD4ijUCjnebYIrjvVdw)  
摘要：最近关于BERT压缩的文章挺多，这一篇则是来自阿里巴巴的压缩方案 AdaBERT，该方案特点是能针对具体任务得到性能不会显著下降的小型模型。  
论文链接：https://arxiv.org/pdf/2001.04246v1.pdf  
现有的方法是将 BERT 压缩成小型模型，但这种压缩方法与任务无关，也就是说对于不同的下游任务而言，压缩方法是一样的。  
面向任务的 BERT 压缩方法是有必要的而且很有用，为此阿里巴巴的研究者提出了一种全新的压缩方法 AdaBERT。该方法利用了可微神经架构搜索来自动将 BERT 压缩成适应不同特定任务的小型模型。  
研究者为 AdaBERT 提出了两种不同的损失函数。一是面向任务的知识注入损失，可为搜索过程提供提示；二是效率感知型损失，这能提供搜索约束。这两个损失能为任务适应型 BERT 压缩提供效率和有效性之间的平衡。  
研究者在多个 NLP 任务上对 AdaBERT 进行了评估，结果表明这些任务适应型压缩模型在保证表现相当的同时，推理速度比 BERT 快 12.7 到 29.3 倍，同时参数缩小至 BERT 的 11.5 到 17.0 之一的规模。  
- [深度学习可以不要乘法，北大、华为诺亚新论文：加法替代，效果不变，延迟大降 - 知乎](https://zhuanlan.zhihu.com/p/101429498)  
摘要：
https://zhuanlan.zhihu.com/p/101429498

- [第一次胜过MobileNet的二值神经网络，-1与+1的三年艰苦跋涉 | 机器之心](https://mp.weixin.qq.com/s/Xvlxs-Os2meduHrEQFc7vg)  
摘要：来自德国波茨坦大学的 Joseph Bethge 和 Haojin Yang 等研究者提出了 MeliusNet ，其准确度上能击败之前所有二值模型，甚至超越了 MobileNetV1。MeliusNet 的计算复杂度不高，能充分利用二值网络的速度优势。整体而言，MeliusNet 继续在 BNN 定制化架构上进行探索，为二值网络设计了一套高效简洁的架构。  
它主要由 Dense Block 与 Improvement Block 组成。其中 Dense Block 主要用于扩充特征的表达能力，而 Improvement Block 主要用于提升特征的质量。  
论文：MeliusNet: Can Binary Neural Networks Achieve MobileNet-level Accuracy?  
地址：https://arxiv.org/pdf/2001.05936v1.pdf  
- [AAAI 2020] [速度提升200倍，爱奇艺&北航等提出基于耦合知识蒸馏的视频显著区域检测算法 | 机器之心](https://mp.weixin.qq.com/s/VbvCTEYC2FSMAff6bkjAjQ)  
摘要：作者设计了一个超轻量级网络 UVA-Net，并提出了一种基于耦合知识蒸馏的网络训练方法，在视频注意力预测方向的性能可与 11 个最新模型相媲美，而其存储空间仅占用 0.68 MB，在 GPU，CPU 上的FPS分别达到 10、106、404，比之前的模型提升了 206 倍。  
论文链接：https://arxiv.org/pdf/1904.04449.pdf  

## 开源项目

- [阿里开源MNNKit：基于MNN的移动端深度学习SDK，支持安卓和iOS | 机器之心](https://mp.weixin.qq.com/s/ylfoNHnZRailjvb3tDdfSQ)  
摘要：近日，阿里开源了基于 MNN 引擎的项目 MNNKit，面向安卓和 iOS，以 SDK 的方式提供 AI 端侧推理能力，不能把模型从里面掏出来用。Kit的逻辑相比 MNN 比较上层。开发者不需要了解算法细节就可以直接使用。  
目前，MNNKit 已经有人脸检测、手势识别、人像分割等，后续可能有更多 API 接入。  
据悉，MNNKit 是 MNN 团队在阿里系应用大规模业务实践后的成熟解决方案，历经双十一等项目考验，在不依赖于后端的情况下进行高性能推理，使用起来稳定方便。  
项目地址：https://github.com/alibaba/MNNKit  
- [waylonflinn/weblas: GPU Powered BLAS for Browsers](https://github.com/waylonflinn/weblas)  
摘要：GPU accelerated Javascript. Numerical computing in your browser with performance comparable to native. Currently includes hundreds of unit tests, which verify correctness on hundreds of millions of data points.   
Our focus is on numerical operations useful for neural networks and machine learning. So far, we've got 32-bit versions of each of these:  
sscal - Matrix (and Vector) Scale (with addition)  
sgemm - Matrix Multiply  
sdwns - Matrix (and Image) Downsample (for Max Pooling)  
sclmp - Matrix clamp (for ReLU)  
项目地址：https://github.com/waylonflinn/weblas   
- [brendangregg/FlameGraph: Stack trace visualizer](https://github.com/brendangregg/FlameGraph)  
摘要：Flame graphs are a visualization of profiled software, allowing the most frequent code-paths to be identified quickly and accurately. They can be generated using my open source programs on github.com/brendangregg/FlameGraph, which create interactive SVGs.  
文档：http://www.brendangregg.com/flamegraphs.html  
项目：https://github.com/brendangregg/FlameGraph   
- [Facebook开源低延迟在线自动语音识别框架：速度更快，错误率更低 | AI前线](https://mp.weixin.qq.com/s/TjSxiRxCx7A-lz_KorUFrw)  
摘要：Facebook 人工智能研究院（FAIR）开源了基于深度学习的推理框架 wav2letter @ anywhere，该框架可在云或嵌入式边缘环境中快速实现在线自动语音识别。  
Wav2letter @ anywhere 是由 wav2letter 和 wav2letter ++ 这两个基于神经网络的语言模型构建的，在 2018 年 12 月发布时，Facebook 人工智能研究院认为这两款语言模型是目前可用的最快的开源语音识别系统。  
wav2letter 项目地址：
https://github.com/facebookresearch/wav2letter  
- [微软开源ONNX Runtime模型以加速Google BERT | AI前线](https://mp.weixin.qq.com/s/EHYmsSc9OqHcK_54Dw2d4w)  
摘要：微软人工智能研究院 1 月 21 日称计划开源 BERT 自然语言模型优化版本，该模型可以与 ONNX Runtime 推理引擎配合使用。在为 Bing 搜索引擎提供语言表达功能时，Microsoft 使用相同的模型来降低 BERT 的延迟。该模型“为 Bing 用户带来了最佳搜索体验” ，2019年秋天发表的一篇论文中对该模型进行了详细介绍。  
公司发言人表示，这意味着开发人员可以使用 ONNX Runtime 和 Nvidia V100 GPU 大规模部署 BERT，而延迟只有 1.7 毫秒，这样的性能表现过去只能在大型科技公司中实现。  
微软在其他自然语言开发上也取得了一定进展。在 2019 年温哥华 NeurIPS 上，微软和浙江大学联合发布了语音合成系统 FastSpeech，与自回归的 Transformer TTS 相比，FastSpeech 将梅尔谱的生成速度提高了近 270 倍，将端到端语音合成速度提高了 38 倍，单 GPU 上的语音合成速度达到了实时语音速度的 30 倍。  
原文地址：https://azure.microsoft.com/en-us/blog/bing-delivers-its-largest-improvement-in-search-experience-using-azure-gpus/  


## 博文

- [cnn结构设计技巧-兼顾速度精度与工程实现 | 知乎](https://zhuanlan.zhihu.com/p/100609339)  
摘要：CNN结构设计技巧，本文从分割、low-level、检测、metric learning、分类、landmark、视频理解、3D等角度对CNN的结构设计进行了解读，非常值得一看。  
- [详谈ARM架构与ARM内核发展史 | CSDN云计算](https://mp.weixin.qq.com/s/vhdWstSIeqnCv2fK7abhJA)  
摘要：目前为止，ARM总共发布8种架构：ARMv1、ARMv2、ARMv3、ARMv4、ARMv5、ARMv6、ARMv7 、ARMv8，这是ARM架构指令集的多个v版本。  
基于不同的ARM架构可以设计出不同特点的内核处理器。比如基于ARMv3架构设计出的处理器ARM6、ARM7，这两款处理器适用于不同的场景，硬件可能不同，但是架构指令集是一样的。  
- [5nm工艺问世，CPU工艺与性能是一种什么样的关系 | strongerHuang](https://mp.weixin.qq.com/s/4z-4Fd17BT7tnVe5iLNTBw)  
摘要：现在半导体工艺上所说的多少nm工艺其实是指线宽，也就是芯片上的最基本功能单位门电路的宽度，因为实际上门电路之间连线的宽度同门电路的宽度相同，所以线宽可以描述制造工艺。缩小线宽意味着晶体管可以做得更小、更密集，而且在相同的芯片复杂程度下可使用更小的晶圆，于是成本降低了。  
更先进半导体制造工艺另一个重要优点就是可以提升工作频率，缩减元件之间的间距之后，晶体管之间的电容也会降低，晶体管的开关频率也得以提升，从而整个芯片的工作频率就上去了。  
- [深度学习加速：算法、编译器、体系结构与硬件设计 | 知乎](https://zhuanlan.zhihu.com/p/101544149)  
摘要：NeurlPS2019 大会的「Efficient Processing of Deep Neural Network: from Algorithms to Hardware Architectures」的演讲概括性地介绍了目前深度学习加速领域的进展，这个演讲的逻辑清晰，结合演讲ppt内容和近期调研的一些加速器相关内容，总括性地理一下深度学习加速领域的内容。首先关于深度学习加速，一般会想到的就是关于深度学习加速器的硬件设计，但其实更宽泛地讲，从算法顶层，到编译器，到体系结构，硬件最底层都有涉及。下面的介绍也大致围绕这几个方面展开。  
- [用 TensorFlow Lite 实现设备端个性化模型 | TensorFlow](https://mp.weixin.qq.com/s/4tBJplpdhceBw6z_vO3Cag)  
摘要：虽然 TensorFlow Lite 训练解决方案仍在开发中，但已有设备端上座迁移学习的例子了。本文会向您介绍可现学现用的设备端机器学习模型个性化方法、使用场景，以及这背后的工作原理。  
现有的例子有一个 Android 应用可学习对相机图像进行实时分类，使用迁移学习技术，这款应用能够在所有适用的最新 Android 设备（系统版本为 5.0 及以上）上运行。在此应用中，我们可以针对不同目标类别拍摄样本照片，然后在设备端对其进行训练。
该应用会对 MobileNetV2 量化模型在端上使用迁移学习技术，而我们先前已（在服务器上）基于 ImageNet 对该模型进行了预训练，并将最后几层替换成可训练的 softmax 分类器。可以通过训练最后几层来识别四个任意的新类别，而准确率则取决于要捕获的类别的“难度”。我们观察到，即使只有数十个样本，也足以取得良好的结果。


## [往期回顾](https://github.com/ysh329/awesome-embedded-ai)

- [2020-01-06](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2020-01-06.md)
- [2019-12-17](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-12-17.md)
- [2019-12-02](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-12-02.md)
- [2019-11-18](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-11-18.md)
- [2019-10-31](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-10-31.md)
- [2019-10-17](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-10-17.md)  
- [2019-10-03](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-10-03.md)  
- [2019-09-16](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-09-16.md)
- [2019-08-30](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-08-30.md)
- [2019-08-15](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-08-15.md)
- [2019-07-30](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-07-30.md)
- [2019-07-15](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-07-15.md)
- [2019-06-29](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-06-29.md)
- [2019-06-17](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-06-17.md)
- [2019-05-30](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-05-30.md)  
- [2019-05-15](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-05-15.md)  
- [2019-04-27](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-04-27.md)  
- [2019-04-13](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-04-13.md)  
- [2019-03-31](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-03-31.md)  

----

![wechat_qrcode](../wechat_qrcode.jpg)

Wechat ID: NeuroMem  
Editor: https://github.com/ysh329  
Project: https://github.com/ysh329/awesome-embedded-ai  

----

<a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"><img alt="知识共享许可协议" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" /></a><br />本作品采用<a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">知识共享署名-相同方式共享 4.0 通用许可协议</a>进行许可。
