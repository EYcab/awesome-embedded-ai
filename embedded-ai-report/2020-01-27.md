---
layout: default
---

# 嵌入式AI简报 (2020-01-27)

**关注模型压缩、低比特量化、移动端推理加速优化、部署**  


## 业界新闻

- iPhone 12采用5纳米A14处理器，性能堪比MacBook Pro | IT之家  
摘要：1月17日，据国外媒体报道， iPhone 12将采用5纳米制造工艺的A14处理器，配备ToF 3D摄像头（AR能力和人像模式显著提升）和6GB RAM，支持5G网络。5纳米工艺意味着A14芯片可能拥有125亿个晶体管，甚至比桌面和服务器CPU更多。此外，苹果还可以将芯片面积缩小至约85平方毫米，这将使其性能大幅提升，尤其是在多核性能方面。有分析师称，iPhone 12的性能几乎可以匹敌15英寸MacBook Pro笔记本电脑。  
- [Qualcomm推出三款全新骁龙移动平台460，662，720以满足对4G智能手机的持续需求 | Qualcomm中国](https://mp.weixin.qq.com/s/2BO_UXIY1qGoqLlp5tdYMQ)  
摘要：因为比较关注CPU/GPU/DSP部分，简单摘录了一下。  
骁龙720G支持最新的第五代Qualcomm® AI Engine，集成了增强的Qualcomm® Hexagon™张量加速器。  
骁龙460是面向新一代大众市场智能手机的移动平台，在骁龙4系中实现了性能的巨大飞跃，同时在连接、AI和拍摄等方面也有显著的提升。骁龙460首次在骁龙4系中引入CPU性能内核以及新的GPU架构，分别实现了70%和60%的性能提升。整体系统性能是前代平台的2倍。骁龙460还首次在骁龙4系中引入了支持HVX的Hexagon处理器，因此通过对第三代Qualcomm AI Engine的支持再加上Qualcomm传感器中枢，可为拍摄和语音助理带来全新的AI体验。  
骁龙662首次将令人惊叹的拍摄和AI功能带入骁龙6系。支持Hexagon向量扩展内核（HVX）的第三代Qualcomm AI Engine与Qualcomm Spectra 340T ISP一起。

## 论文

- [推理速度提升29倍，参数少1/10，阿里提出AdaBERT压缩方法 | 机器之心](https://mp.weixin.qq.com/s/mObuD4ijUCjnebYIrjvVdw)  
摘要：最近关于BERT压缩的文章挺多，这一篇则是来自阿里巴巴的压缩方案 AdaBERT，该方案特点是能针对具体任务得到性能不会显著下降的小型模型。  
论文链接：https://arxiv.org/pdf/2001.04246v1.pdf  
现有的方法是将 BERT 压缩成小型模型，但这种压缩方法与任务无关，也就是说对于不同的下游任务而言，压缩方法是一样的。  
面向任务的 BERT 压缩方法是有必要的而且很有用，为此阿里巴巴的研究者提出了一种全新的压缩方法 AdaBERT。该方法利用了可微神经架构搜索来自动将 BERT 压缩成适应不同特定任务的小型模型。  
研究者为 AdaBERT 提出了两种不同的损失函数。一是面向任务的知识注入损失，可为搜索过程提供提示；二是效率感知型损失，这能提供搜索约束。这两个损失能为任务适应型 BERT 压缩提供效率和有效性之间的平衡。  
研究者在多个 NLP 任务上对 AdaBERT 进行了评估，结果表明这些任务适应型压缩模型在保证表现相当的同时，推理速度比 BERT 快 12.7 到 29.3 倍，同时参数缩小至 BERT 的 11.5 到 17.0 之一的规模。  
- [深度学习可以不要乘法，北大、华为诺亚新论文：加法替代，效果不变，延迟大降 - 知乎](https://zhuanlan.zhihu.com/p/101429498)  
摘要：
https://zhuanlan.zhihu.com/p/101429498

## 开源项目

- [阿里开源MNNKit：基于MNN的移动端深度学习SDK，支持安卓和iOS | 机器之心](https://mp.weixin.qq.com/s/ylfoNHnZRailjvb3tDdfSQ)  
摘要：近日，阿里开源了基于 MNN 引擎的项目 MNNKit，面向安卓和 iOS，以 SDK 的方式提供 AI 端侧推理能力。开发者不需要了解算法细节就可以直接使用。  
目前，MNNKit 已经有人脸检测、手势识别、人像分割等，后续可能有更多 API 接入。  
据悉，MNNKit 是 MNN 团队在阿里系应用大规模业务实践后的成熟解决方案，历经双十一等项目考验，在不依赖于后端的情况下进行高性能推理，使用起来稳定方便。  
项目地址：https://github.com/alibaba/MNNKit  
- [brendangregg/FlameGraph: Stack trace visualizer](https://github.com/brendangregg/FlameGraph)  
摘要：Flame graphs are a visualization of profiled software, allowing the most frequent code-paths to be identified quickly and accurately. They can be generated using my open source programs on github.com/brendangregg/FlameGraph, which create interactive SVGs.  
文档：http://www.brendangregg.com/flamegraphs.html  
项目：https://github.com/brendangregg/FlameGraph   
- [Facebook开源低延迟在线自动语音识别框架：速度更快，错误率更低 | AI前线](https://mp.weixin.qq.com/s/TjSxiRxCx7A-lz_KorUFrw)  
摘要：Facebook 人工智能研究院（FAIR）开源了基于深度学习的推理框架 wav2letter @ anywhere，该框架可在云或嵌入式边缘环境中快速实现在线自动语音识别。  
Wav2letter @ anywhere 是由 wav2letter 和 wav2letter ++ 这两个基于神经网络的语言模型构建的，在 2018 年 12 月发布时，Facebook 人工智能研究院认为这两款语言模型是目前可用的最快的开源语音识别系统。  
wav2letter 项目地址：
https://github.com/facebookresearch/wav2letter  
- [微软开源ONNX Runtime模型以加速Google BERT | AI前线](https://mp.weixin.qq.com/s/EHYmsSc9OqHcK_54Dw2d4w)  
摘要：微软人工智能研究院 1 月 21 日称计划开源 BERT 自然语言模型优化版本，该模型可以与 ONNX Runtime 推理引擎配合使用。在为 Bing 搜索引擎提供语言表达功能时，Microsoft 使用相同的模型来降低 BERT 的延迟。该模型“为 Bing 用户带来了最佳搜索体验” ，2019年秋天发表的一篇论文中对该模型进行了详细介绍。  
公司发言人表示，这意味着开发人员可以使用 ONNX Runtime 和 Nvidia V100 GPU 大规模部署 BERT，而延迟只有 1.7 毫秒，这样的性能表现过去只能在大型科技公司中实现。  
微软在其他自然语言开发上也取得了一定进展。在 2019 年温哥华 NeurIPS 上，微软和浙江大学联合发布了语音合成系统 FastSpeech，与自回归的 Transformer TTS 相比，FastSpeech 将梅尔谱的生成速度提高了近 270 倍，将端到端语音合成速度提高了 38 倍，单 GPU 上的语音合成速度达到了实时语音速度的 30 倍。  
原文地址：https://azure.microsoft.com/en-us/blog/bing-delivers-its-largest-improvement-in-search-experience-using-azure-gpus/  


## 博文

- [5nm工艺问世，CPU工艺与性能是一种什么样的关系 | strongerHuang](https://mp.weixin.qq.com/s/4z-4Fd17BT7tnVe5iLNTBw)  
摘要：现在半导体工艺上所说的多少nm工艺其实是指线宽，也就是芯片上的最基本功能单位门电路的宽度，因为实际上门电路之间连线的宽度同门电路的宽度相同，所以线宽可以描述制造工艺。缩小线宽意味着晶体管可以做得更小、更密集，而且在相同的芯片复杂程度下可使用更小的晶圆，于是成本降低了。  
更先进半导体制造工艺另一个重要优点就是可以提升工作频率，缩减元件之间的间距之后，晶体管之间的电容也会降低，晶体管的开关频率也得以提升，从而整个芯片的工作频率就上去了。  
- [深度学习加速：算法、编译器、体系结构与硬件设计 | 知乎](https://zhuanlan.zhihu.com/p/101544149)  
摘要：NeurlPS2019 大会的「Efficient Processing of Deep Neural Network: from Algorithms to Hardware Architectures」的演讲概括性地介绍了目前深度学习加速领域的进展，这个演讲的逻辑清晰，结合演讲ppt内容和近期调研的一些加速器相关内容，总括性地理一下深度学习加速领域的内容。首先关于深度学习加速，一般会想到的就是关于深度学习加速器的硬件设计，但其实更宽泛地讲，从算法顶层，到编译器，到体系结构，硬件最底层都有涉及。下面的介绍也大致围绕这几个方面展开。  




## [往期回顾](https://github.com/ysh329/awesome-embedded-ai)

- [2020-01-06](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2020-01-06.md)
- [2019-12-17](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-12-17.md)
- [2019-12-02](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-12-02.md)
- [2019-11-18](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-11-18.md)
- [2019-10-31](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-10-31.md)
- [2019-10-17](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-10-17.md)  
- [2019-10-03](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-10-03.md)  
- [2019-09-16](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-09-16.md)
- [2019-08-30](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-08-30.md)
- [2019-08-15](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-08-15.md)
- [2019-07-30](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-07-30.md)
- [2019-07-15](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-07-15.md)
- [2019-06-29](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-06-29.md)
- [2019-06-17](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-06-17.md)
- [2019-05-30](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-05-30.md)  
- [2019-05-15](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-05-15.md)  
- [2019-04-27](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-04-27.md)  
- [2019-04-13](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-04-13.md)  
- [2019-03-31](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-03-31.md)  

----

![wechat_qrcode](../wechat_qrcode.jpg)

Wechat ID: NeuroMem  
Editor: https://github.com/ysh329  
Project: https://github.com/ysh329/awesome-embedded-ai  

----

<a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"><img alt="知识共享许可协议" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" /></a><br />本作品采用<a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">知识共享署名-相同方式共享 4.0 通用许可协议</a>进行许可。
